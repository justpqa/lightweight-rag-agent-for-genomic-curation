{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6caa7e8",
   "metadata": {},
   "source": [
    "### Test different LLM settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from langchain_core.documents import Document\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from ingest import ingest_corpus, verify_db_existence\n",
    "from rag import RAG \n",
    "from dotenv import load_dotenv  \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4acaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import questions\n",
    "queries = []\n",
    "with open(\"./queries.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        queries.append(obj)\n",
    "print(len(queries), \"queries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d396889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test rag questiona and answering\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def question_answer_similarity(question: str, answer: str) -> float:\n",
    "    question_embeddings = model.encode(question)\n",
    "    answer_embeddings = model.encode(answer)\n",
    "    scores = util.cos_sim(question_embeddings, answer_embeddings)\n",
    "    return scores.item()\n",
    "\n",
    "def citation_answer_max_and_min_similarity(citations: List[Document], answer: str) -> Tuple[float, float]:\n",
    "    answer_embeddings = model.encode(answer)\n",
    "    citation_texts = [citation.page_content for citation in citations]\n",
    "    citation_embeddings = model.encode(citation_texts)\n",
    "    scores = util.cos_sim(answer_embeddings, citation_embeddings)\n",
    "    max_score = scores.max().item()\n",
    "    min_score = scores.min().item()\n",
    "    return max_score, min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different configurations to test\n",
    "# chunk size, top_k, top_k_rerank\n",
    "configurations = [\n",
    "    [500, 20, 5],\n",
    "    [500, 50, 5],\n",
    "    [500, 50, 10],\n",
    "    [1000, 20, 5]\n",
    "] # due to limited time, we only examine 3 configurations here\n",
    "\n",
    "# Run tests\n",
    "result_df = {\n",
    "    \"chunk_size\": [],\n",
    "    \"top_k\": [],\n",
    "    \"top_k_rerank\": [],\n",
    "    \"query\": [],\n",
    "    \"answer_without_citation\": [],\n",
    "    \"qa_similarity\": [],\n",
    "    \"citation_answer_max_similarity\": [],\n",
    "    \"citation_answer_min_similarity\": []\n",
    "}\n",
    "for (chunk_size, top_k, top_k_rerank) in configurations:\n",
    "    ingest_corpus(chroma_db_path=\"./test_chroma_db\", chunk_size=chunk_size, print_progress=False)\n",
    "    print(f\"Testing configuration: chunk_size={chunk_size}, top_k={top_k}, top_k_rerank={top_k_rerank}\")\n",
    "    rag = RAG(\n",
    "        chroma_db_path=\"./test_chroma_db\",\n",
    "        top_k=top_k,\n",
    "        top_k_rerank=top_k_rerank,\n",
    "        print_progress=False\n",
    "    )\n",
    "    for query_obj in tqdm(queries):\n",
    "        question = query_obj[\"question\"]\n",
    "        retrieved_docs = rag.retrieve(question)\n",
    "        answer = rag.answer(question, with_citation=False) # not generate with citation to only consider the llm output\n",
    "        # Calculate similarities\n",
    "        qa_similarity = question_answer_similarity(question, answer)\n",
    "        max_citation_sim, min_citation_sim = citation_answer_max_and_min_similarity(retrieved_docs, answer)\n",
    "        # Store results\n",
    "        result_df[\"chunk_size\"].append(chunk_size)\n",
    "        result_df[\"top_k\"].append(top_k)\n",
    "        result_df[\"top_k_rerank\"].append(top_k_rerank)\n",
    "        result_df[\"query\"].append(question)\n",
    "        result_df[\"answer_without_citation\"].append(answer)\n",
    "        result_df[\"qa_similarity\"].append(qa_similarity)\n",
    "        result_df[\"citation_answer_max_similarity\"].append(max_citation_sim)\n",
    "        result_df[\"citation_answer_min_similarity\"].append(min_citation_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9423d151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>top_k</th>\n",
       "      <th>top_k_rerank</th>\n",
       "      <th>query</th>\n",
       "      <th>answer_without_citation</th>\n",
       "      <th>qa_similarity</th>\n",
       "      <th>citation_answer_max_similarity</th>\n",
       "      <th>citation_answer_min_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>What is known about APOE and Alzheimer’s disease?</td>\n",
       "      <td>The provided citations discuss the role of APO...</td>\n",
       "      <td>0.865631</td>\n",
       "      <td>0.870943</td>\n",
       "      <td>0.627306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>How do TREM2 variants influence the risk of Al...</td>\n",
       "      <td>The provided citations highlight the role of T...</td>\n",
       "      <td>0.871481</td>\n",
       "      <td>0.856757</td>\n",
       "      <td>0.626495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>What evidence links ABCA7 to Alzheimer’s patho...</td>\n",
       "      <td>The provided citations discuss the role of the...</td>\n",
       "      <td>0.818911</td>\n",
       "      <td>0.840042</td>\n",
       "      <td>0.513437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Are there genetic loci associated with early-o...</td>\n",
       "      <td>A genome-wide association study (GWAS) has ide...</td>\n",
       "      <td>0.829213</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.668779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Which biological pathways are most commonly im...</td>\n",
       "      <td>Recent genomic studies have identified several...</td>\n",
       "      <td>0.632450</td>\n",
       "      <td>0.729587</td>\n",
       "      <td>0.494551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_size  top_k  top_k_rerank  \\\n",
       "0         500     20             5   \n",
       "1         500     20             5   \n",
       "2         500     20             5   \n",
       "3         500     20             5   \n",
       "4         500     20             5   \n",
       "\n",
       "                                               query  \\\n",
       "0  What is known about APOE and Alzheimer’s disease?   \n",
       "1  How do TREM2 variants influence the risk of Al...   \n",
       "2  What evidence links ABCA7 to Alzheimer’s patho...   \n",
       "3  Are there genetic loci associated with early-o...   \n",
       "4  Which biological pathways are most commonly im...   \n",
       "\n",
       "                             answer_without_citation  qa_similarity  \\\n",
       "0  The provided citations discuss the role of APO...       0.865631   \n",
       "1  The provided citations highlight the role of T...       0.871481   \n",
       "2  The provided citations discuss the role of the...       0.818911   \n",
       "3  A genome-wide association study (GWAS) has ide...       0.829213   \n",
       "4  Recent genomic studies have identified several...       0.632450   \n",
       "\n",
       "   citation_answer_max_similarity  citation_answer_min_similarity  \n",
       "0                        0.870943                        0.627306  \n",
       "1                        0.856757                        0.626495  \n",
       "2                        0.840042                        0.513437  \n",
       "3                        0.836590                        0.668779  \n",
       "4                        0.729587                        0.494551  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(result_df)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd79e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_size</th>\n",
       "      <th>top_k</th>\n",
       "      <th>top_k_rerank</th>\n",
       "      <th>qa_similarity</th>\n",
       "      <th>citation_answer_max_similarity</th>\n",
       "      <th>citation_answer_min_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.822992</td>\n",
       "      <td>0.805708</td>\n",
       "      <td>0.582623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.790218</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.517048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.778366</td>\n",
       "      <td>0.812251</td>\n",
       "      <td>0.520168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.777831</td>\n",
       "      <td>0.783236</td>\n",
       "      <td>0.539775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_size  top_k  top_k_rerank  qa_similarity  \\\n",
       "0         500     20             5       0.822992   \n",
       "1         500     50             5       0.790218   \n",
       "2         500     50            10       0.778366   \n",
       "3        1000     20             5       0.777831   \n",
       "\n",
       "   citation_answer_max_similarity  citation_answer_min_similarity  \n",
       "0                        0.805708                        0.582623  \n",
       "1                        0.834320                        0.517048  \n",
       "2                        0.812251                        0.520168  \n",
       "3                        0.783236                        0.539775  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean resumes\n",
    "result_mean_df = result_df.groupby([\"chunk_size\",  \"top_k\", \"top_k_rerank\"], as_index = False)[[\"qa_similarity\", \"citation_answer_max_similarity\", \"citation_answer_min_similarity\"]].mean()\n",
    "result_mean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a9499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"./test_results.csv\", index=False)\n",
    "result_mean_df.to_csv(\"./test_results_mean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
